{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import babypandas as bpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DSC 10 - Final Exam Review\n",
    "\n",
    "<img src=\"data/panda.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Final Exam\n",
    "\n",
    "### Saturday, July 31st\n",
    "\n",
    "- Available in a 24 hour window.\n",
    "- 3 hours to complete; designed to take less.\n",
    "- Cumulative.\n",
    "- Open book, open note, open everything (but no talking about the exam)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Final Project\n",
    "\n",
    "- Don't forget: due this week on July 31st.\n",
    "- Excellent practice for the final exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Final Discussion\n",
    "\n",
    "- The stuff from the second part of the quarter was more *conceptual*.\n",
    "- The final exam will therefore have more *conceptual* questions.\n",
    "- Here, we'll review the main concepts from second part of the quarter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concept 1: Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distributions\n",
    "\n",
    "- A *ditribution* tells us the probability of each possible outcome.\n",
    "- Often visualized with a *histogram*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = bpd.read_csv('data/united_summer2015.csv')\n",
    "flights.plot(kind='hist', y='Delay', bins=20, density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concept 2: Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Populations and Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The *population* is the \"entire\" data set. We don't usually see it.\n",
    "- Instead, we see a *sample* whose size is smaller than the population.\n",
    "- We usually obtain the sample *randomly*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## With/Without Replacement\n",
    "\n",
    "- We have the option to randomly sample with/without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.sample(2000, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examples\n",
    "\n",
    "In each of the following experiments, 1) what is the population? 2) should we sample with or without replacement?\n",
    "\n",
    "- Picking a team of 5 from a class of 100 people.\n",
    "- Rolling a 6-sided die, 20 times.\n",
    "- Randomly generating names for 100 babies born."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concept 3: Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We want to know some aspect (parameter) of the *population*.\n",
    "    - Example: the average flight delay, or total number of planes produced\n",
    "- We don't have the population, only a sample.\n",
    "- So we try to *estimate* the parameter using the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistics\n",
    "\n",
    "- A statistic is any number computed from a sample.\n",
    "- We compute a *statistic* to *estimate* a population *parameter*.\n",
    "- Example: sample mean flight delay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Problem\n",
    "\n",
    "- You randomly select a sample and compute your statistic.\n",
    "    - Example: the sample mean flight delay is 14 minutes.\n",
    "- Your hope: it is close to the \"right answer\" (the pop. mean).\n",
    "- You can never know *exactly* how close it is without having the population.\n",
    "- The power of statistics: you can say how *likely* it is to be within a certain distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sampling Distribution\n",
    "\n",
    "- The sample is random; so your sample statistic is, too.\n",
    "- I.e., it could have been different.\n",
    "- The *sampling distribution* tells us the probability of those different outcomes.\n",
    "- I.e., it tells us how different sample mean *could have been*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_mean = population.sample(2000).get('Delay').mean()\n",
    "observed_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simulating the Sampling Distribution\n",
    "\n",
    "- Let's get more samples from the population, compute mean of each.\n",
    "- **Problem**: In the real world we (usually) can't do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_means = np.array([])\n",
    "for i in np.arange(1000):\n",
    "    mean = population.get('Delay').sample(2000).mean()\n",
    "    sample_means = np.append(sample_means, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample_means)\n",
    "plt.scatter(observed_mean, 0, color='red', zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sampling Distribution\n",
    "\n",
    "- We'd love to know the sampling distribution.\n",
    "- But we just have one sample.\n",
    "- How do we approximate the sampling distribution with just one sample?\n",
    "- Answers: the Bootstrap and the Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concept 4: The Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Boostrap\n",
    "\n",
    "- Problem: we want to know the sample distribution of our statistic, but we just have one sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sample = population.sample(2000)\n",
    "plt.hist(sample_means, alpha=.1, color='black')\n",
    "plt.scatter(original_sample.get('Delay').mean(), 0, color='red', zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Idea\n",
    "\n",
    "- I wish I had the population; then I could get more samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_sample = population.sample(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I don't have the population.\n",
    "- But hey, the original sample probably looks like the population. Let's sample from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_sample = original_sample.sample(2000, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Boostrapping and Replacement\n",
    "\n",
    "- **Important**: when we get a boostrap sample, we sample *with* replacement. Why?\n",
    "- If we didn't we'd just get the same data set back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sample.sample(2000, replace=True).get('Delay').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bootstrapping and Duplicates\n",
    "\n",
    "- If we sample with replacement, we'll get duplicates.\n",
    "- This is OK! In fact, it is necessary.\n",
    "- The mean doesn't care about duplicates.\n",
    "    - mean of [1.9, 2.1, 6.1, 6.2] is $\\approx$ mean of [2, 2, 6, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    original_sample.sample(1000, replace=True).plot(kind='hist', y='Delay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_sample_means = np.array([])\n",
    "for i in np.arange(5000):\n",
    "    bootstrap_sample_mean = original_sample.get('Delay').sample(original_sample.shape[0], replace=True).mean()\n",
    "    bootstrap_sample_means = np.append(bootstrap_sample_means, bootstrap_sample_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bootstrap_sample_means, density=True)\n",
    "plt.hist(sample_means, density=True, alpha=.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concept 5: The Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The CLT\n",
    "\n",
    "- Problem: we want to know the sample distribution of our statistic, but we just have one sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sample = population.sample(2000)\n",
    "plt.hist(sample_means, alpha=.1, color='black')\n",
    "plt.scatter(original_sample.get('Delay').mean(), 0, color='red', zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Idea\n",
    "\n",
    "- Some smart people proved that the distribution of the *sample mean* will be (approximately) normal.\n",
    "- This is the **Central Limit Theorem**:\n",
    "\n",
    "> The sampling distribution of the sample mean is approximately a normal curve, centered at the population mean, and with standard deviation equal to the population standard deviation over the square root of the sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CLT\n",
    "\n",
    "- The CLT let's us approximate the sample distribution of the mean without getting more samples or running the bootstrap.\n",
    "- Small problem: we don't have the sample mean/SD. That's OK, just use the sample mean/SD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Careful!\n",
    "\n",
    "- There are lots of distributions here. The population distribution, the sample distribution, and the distribution of the sample mean, each with their own mean / SD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.plot(kind='hist', y='Delay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sample.plot(kind='hist', y='Delay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x, mu, sigma):\n",
    "    return 1/np.sqrt(2 * np.pi * sigma**2) * np.exp(-0.5 * (x - mu)**2 / sigma**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = original_sample.get('Delay').mean()\n",
    "sigma = np.std(original_sample.get('Delay')) / np.sqrt(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_clt = np.linspace(14, 20, 100)\n",
    "y_clt = norm(x_clt, mu, sigma)\n",
    "plt.plot(x_clt, y_clt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CLT vs Boostrapping\n",
    "\n",
    "- The CLT and Boostrapping are two ways of approximating a sampling distribution.\n",
    "    - How different could our estimate have been?\n",
    "- However, the CLT is **only** useful when talking about the sample mean (or sample sum).\n",
    "- The boostrap is more generally useful. Example: the sample median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When to use the CLT vs the Boostrap\n",
    "\n",
    "- If we're talking about the sample mean, use the CLT.\n",
    "- *Could* use the boostrap, but it's less accurate/slower.\n",
    "- If we're talking about another statistic (e.g., median), use the bootstrap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concept 6: Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confidence Intervals\n",
    "\n",
    "- How different could our estimate have been?\n",
    "- Instead of giving a single estimate, give an interval and a \"confidence level\".\n",
    "- E.g., \"I'm 95% sure that the population mean flight delay is between 14 and 17\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CIs and the Sampling Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we have a sampling distribution, we can construct a CI (no matter how we got the sampling distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample_means, density=True)\n",
    "plt.plot(x_clt, y_clt)\n",
    "plt.hist(bootstrap_sample_means, density=True, alpha=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Constructing CIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An $x$% CI contains the middle $x$% of the sampling distribution.\n",
    "- Two ways:\n",
    "    1. If we have a bunch of sample statistics (like from the boostrap), we can use `np.percentile`.\n",
    "    2. If we're using the CLT, we can use the rule of thumb: 95% of normal curve is within 2 SDs of mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: From the Actual Sampling Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "[left_sms, right_sms] = np.percentile(sample_means, 2.5), np.percentile(sample_means, 97.5)\n",
    "[left_sms, right_sms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample_means)\n",
    "plt.plot([left_sms, right_sms], [0,0], color='lime', linewidth=10, zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: From the Boostrap Sampling Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "[left_boot, right_boot] = np.percentile(bootstrap_sample_means, 2.5), np.percentile(bootstrap_sample_means, 97.5)\n",
    "[left_boot, right_boot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bootstrap_sample_means, color='C2')\n",
    "plt.plot([left_boot, right_boot], [0,0], color='lime', linewidth=10, zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: From the CLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "[left_clt, right_clt] = [\n",
    "    original_sample.get('Delay').mean() - 2 * np.std(original_sample.get('Delay')) / np.sqrt(2000),\n",
    "    original_sample.get('Delay').mean() + 2 * np.std(original_sample.get('Delay')) / np.sqrt(2000),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_clt, y_clt, color='C1')\n",
    "plt.plot([left_clt, right_clt], [0,0], color='lime', linewidth=10, zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([left_clt, right_clt], [.2, .2], color='C1', linewidth=10, zorder=10)\n",
    "plt.plot([left_boot, right_boot], [.1,.1], color='C2', linewidth=10, zorder=10)\n",
    "plt.plot([left_sms, right_sms], [0,0], color='C0', linewidth=10, zorder=10)\n",
    "plt.scatter(population.get('Delay').mean(), -.1, color='black', s=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Accuracy\n",
    "\n",
    "- The Boostrap and CLT are *approximations*.\n",
    "- As the sample size increases, they get better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concept 7: Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assessing Models\n",
    "\n",
    "- We have a *model* of reality (a set of assumptions)\n",
    "    - Example: jury panels are selected at random from eligible population\n",
    "- Is the model plausible or unlikely?\n",
    "- We can use probability and simulation to assess its likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Null and Alternative Hypotheses\n",
    "\n",
    "- The *null* hypothesis is the \"default\", \"boring\" model of reality.\n",
    "- The *alternative* hypothesis is the interesting one.\n",
    "- The null hypothesis is (usually) precise and specific enough that it allows us to simulate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "I think a coin is unfair. To test it, I make the following hypotheses:\n",
    "\n",
    "- Null: the coin is fair\n",
    "- Alternative: the coin is not fair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "I think a coin is *biased towards heads*. I make the following hypotheses:\n",
    "    \n",
    "- Null: the coin is fair\n",
    "- Alternative: the coin is unfair and biased towards heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workflow\n",
    "\n",
    "- Is the null hypothesis false?\n",
    "- Flip the coin a bunch, count *observed* numbers of heads.\n",
    "- Is what we observed consistent with the null model, or very unlikely?\n",
    "- We need probability of seeing observed under the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test Statistics\n",
    "\n",
    "- We must have a way of measuring how far we are from what is expected under the null.\n",
    "- We need to choose a *test statistic*.\n",
    "- The larger the test statistic, the more extreme.\n",
    "- Choice depends on the *alternative* hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "- Alternative: the coin is not fair\n",
    "- Possible test statistics:\n",
    "    - the absolute difference between proportion of heads and 50%\n",
    "    - the absolute difference between number of heads and 50\n",
    "    - the TVD between sample distribution of heads/tails and the uniform distribution\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "- Alternative: the coin is not fair, and *biased towards heads*.\n",
    "- The statistic should be larger the more extreme the outcome.\n",
    "- Possible test statistics:\n",
    "    - the number of heads\n",
    "    - the signed difference between the number of heads and 50\n",
    "    - the signed difference between the proportion of heads and 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "- You flip a coin 100 times and see 57 heads.\n",
    "- Test alternative hypothesis: coin is biased towards heads.\n",
    "- I.e., what is the probability of seeing 57 heads if coin is indeed fair?\n",
    "- This is the *p-value*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "counts = np.array([])\n",
    "for i in np.arange(1000):\n",
    "    # flip fair coin 100 times\n",
    "    flips = np.random.choice(['H', 'T'], 100)\n",
    "    \n",
    "    count = np.count_nonzero(flips == 'H')\n",
    "    counts = np.append(counts, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(counts >= 57) / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rejecting and Failing to Reject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The p-value tells us the probability of seeing the observed outcome if the null is true.\n",
    "- If we had set a \"confidence threshold\" before the experiment, we can reject at that confidence level.\n",
    "- E.g., if we had set a 5% threshold (95% confidence) we would fail to reject.\n",
    "- Still, a p-value of $\\approx$ 10% means that we were getting close to rejecting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accepting a null hypothesis?\n",
    "\n",
    "- We never \"accept\" a null hypothesis, we only \"fail to reject\". Why?\n",
    "- If we see 50 heads and 50 tails, this isn't evidence that the coin is fair; only that it is close to fair.\n",
    "- It would be wrong to say that we are \"95% sure that the coin is fair\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concept 8: A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A/B Testing\n",
    "\n",
    "- A type of hypothesis test.\n",
    "- We have two groups. Do they come from the same distribution?\n",
    "- Example: baby weights for mothers who smoked / didn't smoke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Idea\n",
    "\n",
    "- The null hypothesis: they come from the same distribution.\n",
    "- We can't directly simulate using the null.\n",
    "- Permuting group labels is like sampling more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Permutation Tests\n",
    "\n",
    "- Given a table, one column with group labels, another with quantity of interest.\n",
    "- Repeatedly:\n",
    "    - Shuffle the group labels.\n",
    "    - Compute a test statistic measuring difference between groups.\n",
    "- Plot the distribution of differences, use to calculate p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concept 9: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets make a scatter plot:\n",
    " - Below is some randomlly generated data, normally you would use real world data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create some random data\n",
    "randomData = bpd.DataFrame(data = {\n",
    "    \"Data_A\" : (np.random.randint(0,100,size=(200)))\n",
    "}, index=np.arange(200))\n",
    "\n",
    "# create a random set of data that is +/-20 from generated Data A  \n",
    "randomCol = randomData.get('Data_A')\n",
    "newCol = np.array([])\n",
    "\n",
    "for i in range(randomCol.shape[0]):\n",
    "    newCol = np.append(newCol, int(randomCol.iloc[i] + np.random.randint(-40,40)))\n",
    "    #check within 0 and 100\n",
    "    if newCol[i] > 100:\n",
    "        newCol[i] = 100\n",
    "    if newCol[i] < 0:\n",
    "        newCol[i] = 0\n",
    "\n",
    "randomData=randomData.assign(Data_B = newCol)\n",
    "\n",
    "\n",
    "#plot the data\n",
    "randomData.plot(kind='scatter', x='Data_A', y='Data_B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting columns to standard units\n",
    "* makes different scatterplots comparable\n",
    "* allows x and y axis to be \"similarly scaled\"\n",
    "    - both axes measure standard deviations from their means\n",
    "* doesn't change shape of the scatterplot (conversion is linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple function to help up standardize the units\n",
    "def standard_units(any_numbers):\n",
    "    \"Convert any array of numbers to standard units.\"\n",
    "    any_numbers = np.array(any_numbers)\n",
    "    return (any_numbers - np.mean(any_numbers))/np.std(any_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets standardize the original (randomlly generated) Data\n",
    "Data_A_su = standard_units(randomData.get('Data_A'))\n",
    "Data_B_su = standard_units(randomData.get('Data_B'))\n",
    "\n",
    "#make a new data frame\n",
    "randomData_su = bpd.DataFrame()\n",
    "randomData_su = randomData_su.assign(Data_A_su = Data_A_su)\n",
    "randomData_su = randomData_su.assign(Data_B_su = Data_B_su)\n",
    "\n",
    "randomData_su\n",
    "\n",
    "#plot the data\n",
    "randomData_su.plot(kind='scatter', x='Data_A_su', y='Data_B_su')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition: Correlation Coefficient\n",
    "\n",
    "**Definition**: The correlation coefficient $r$ of two attributes $x$ and $y$ is the average value of the product of $x$ and $y$ when measured in standard units.\n",
    "\n",
    "* If `x` and `y` are arrays (i.e. columns in a table): \n",
    "```\n",
    "r = np.mean(x_su * y_su)\n",
    "```\n",
    "where `x_su` and `y_su` are `x` and `y` converted to standard units.\n",
    "\n",
    "\n",
    "* Measures how clustered points are around a straight line (linear association)\n",
    "* Based on standard units\n",
    "* $-1 \\leq r \\leq 1$\n",
    "    - $r = 1$: scatterplot is a line of slope 1.\n",
    "    - $r = -1$: scatterplot is a line of slope -1.\n",
    "* $r = 0$: no linear association; *uncorrelated*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = (randomData_su.get('Data_A_su') * randomData_su.get('Data_B_su')).mean()\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the correlation coefficient for prediction\n",
    "In standard units:\n",
    "* The line through $(0,0)$ with slope $r$ is called the regression line.\n",
    "* If the association between attributes is linear, the graph of averages is approximately the regression line.\n",
    "* If the line is given by $f(x) = mx + b$, then the prediction for $x$ is given by $f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression line equation:\n",
    "\n",
    "* In standard units:\n",
    "$$ y = r \\times x $$\n",
    "* In original units, \n",
    "    - where $m_x$, $m_y$ are the averages of $x$ and $y$\n",
    "    - where $s_x$, $s_y$ are the standard deviations of $x$ and $y$,\n",
    "$$\\frac{(y - m_y)}{s_y} = r \\times \\frac{(x - m_x)}{s_x}$$\n",
    "* This equation reworked into the point-slope form of a line:\n",
    "$$(y - m_y) = \\left(\\frac{r\\cdot s_y}{s_x}\\right)(x - m_x)$$\n",
    "\n",
    "* Or in the slope-intercept form:\n",
    "\n",
    "$$y = \\left(\\frac{r\\cdot s_y}{s_x}\\right)x + \\left(m_y - \\frac{r\\cdot s_y\\cdot m_x}{s_x}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slope and intercept\n",
    "\n",
    "* The regression line is given by $y = mx + b$, where:\n",
    "    - the slope $m$ is: $$m = r\\cdot\\frac{SD\\ of\\ x}{SD\\ of\\ y}$$\n",
    "    - the y-intercept $b$ is: $$b = (avg\\ of\\ y) - m\\cdot(avg\\ of\\ x)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the correlation, slop and intercept function\n",
    "def correlation(t, x, y):\n",
    "    return np.mean(standard_units(t.get(x))*standard_units(t.get(y)))\n",
    "\n",
    "def slope(t, x, y):\n",
    "    \"\"\"The slope of the regression line (original units)\"\"\"\n",
    "    r = correlation(t, x, y)\n",
    "    return r * np.std(t.get(y)) / np.std(t.get(x))\n",
    "\n",
    "def intercept(t, x, y):\n",
    "    \"\"\"The intercept of the regression line (original units)\"\"\"\n",
    "    return t.get(y).mean() - slope(t, x, y) * t.get(x).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use our defined functions to find slope and intercept\n",
    "m = slope(randomData, 'Data_A', 'Data_B')\n",
    "b = intercept(randomData, 'Data_A', 'Data_B')\n",
    "\n",
    "print('Slope: ' + str(m) + '  y-intercept: ' + str(b))\n",
    "\n",
    "#polt with our dataFrame:\n",
    "randomData.plot(kind='scatter', x='Data_A', y='Data_B')\n",
    "x = np.arange(0,100)\n",
    "plt.plot(x, m * x + b, color='C1');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
